---
layout: post
title: "2.효율적으로 연관관계 맺기"
description: >
  JPA의 기본 사항을 정리한다.
image: /assets/img/study/jpa.jpg
categories: [ study,jpa ]
related_posts:

---

* toc
{:toc}

## 연관관계 객체 삭제

### **[BAD]** CascadeType.REMOVE vs OrphanRemoval=true

앞에 배웠듯이 @OneToMany - @ManyToOne 양방향 Lazy관계에서 부모에 mappedBy, cascade, orphanRemoval 설정하고 자식에게 JoinColumn을 설정하는 것을
공부했다.<br>
부모에게 설정하는 전이, 고아객체 삭제 설정에 대해 분리해서 알아보자.<br><br><br>

#### orphanRemoval=true,false 차이
{:.read-more}

orphanRemoval=true 설정이 되어있는 경우 부모-자식 연결이 끊기면 자식 엔티티는 DELETE 된다.<br>
orphanRemoval = false 시에는 연결이 끊긴 것에 대한 `UPDATE`만 처리한다.<br>

<br><br><br>

#### CascadeType.REMOVE,OrphanRemoval=true의 결과는 흡사하다.
{:.read-more}

`CascadeType.REMOVE` 설정이 되어있는 경우 부모를 삭제하면 자식을 모두 개별 삭제를 한다.<br>
`orphanRemoval = true` 설정이 되어있는 경우도 동일하게 자식 개별 DELETE를 수행한다. <br>

-> [둘 다 삭제해야할 자식을 개별 삭제 하기 때문에 자식이 많으면 성능저하가 발생한다.](##)

~~~java
//CASCADE REMOVE 삭제 방법 - 부모를 삭제한다. 자식에게 삭제가 전이된다.
@Transactional
public void deleteViaCascadeRemove(){
        Author author=authorRepository.findByName("Joana Numar");
        authorRepository.delete(author);
        }

//ORPHAN REMOVAL 삭제 방법 - 연관관계를 끊어준다.
@Transactional
public void deleteViaOrphanRemoval(){
        Author author=authorRepository.findByNameWithBooks("Joana Numar");

        author.removeBooks();
        authorRepository.delete(author);
        }
~~~

~~~sql
-- file: `CASCADE REMOVE, ORPHAN REMOVAL 쿼리`
[Hibernate]
select a1_0.id,
       a1_0.age,
       a1_0.genre,
       a1_0.name
from author a1_0
where a1_0.name = ?
    [Hibernate]
select b1_0.author_id,
       b1_0.id,
       b1_0.isbn,
       b1_0.title
from book b1_0
where b1_0.author_id = ?
    [Hibernate]
delete
from book
where id = ?
    [Hibernate]
delete
from book
where id = ?
    [Hibernate]
delete
from book
where id = ?
    [Hibernate]
delete
from author
where id = ?
~~~

딱 봐도 엄청나게 비효율적이다.<br>

---

### **[GOOD]** 더 성능 좋은 벌크 delete

CascadeType.REMOVE나 orphanRemoval=true로 삭제하면 자식 개별 DELETE문이 발생해 성능저하.
그래서 벌크 처리를 통해 부모,자식을 삭제한다.<br>
포인트는 자식 삭제 쿼리를 1개만 내뱉게 하는 것이다.<br>
벌크 삭제시 [**영속성 컨텍스트를 무시**](##)하고 JPQL에 명시된 엔티티 삭제만을 진행한다.<br>

#### 단점

* 영속성 콘텍스트는 벌크 작업에 대한 변경을 추적하지 않는다. [자동화된 낙관적 잠금 메커니즘](##) 이점 포기
* CasecadeType.REMOVE, orphanRemoval=true 설정을 무시한다.

> [자동화된 낙관적 잠금 메커니즘의 이점](##)<br>
>
> 여러 트랜잭션이 동시 수정이 이뤄지는 일이 빈번하지 않다는 가정하에 사용한다.<br>
> 별도의 Lock을 걸어 자원에 선점하는 대신, Entity 내부의 @Version 필드를 관리해서<br>
> UPDATE 시에 조회버전과 일치하지 않으면 예외를 발생시켜 동시성 문제를 해결한다.<br>
> <br>
> 읽기 시점에 락을 사용하지 않기 때문에 비관적 락보다 빠르게 조회 및 업데이트가 가능하다.
> {:.note}

#### 장점

* 자식 삭제시 개별 SELECT, DELETE 쿼리를 하지 않아 성능이 좋다.

<br>
벌크 처리시 **`flushAutomatically = true, clearAutomatically = true`** 를 통해 영속성 콘텍스트 동기화 문제를 관리할 수 있다.
동기화의 고민은 [**영속성 콘텍스트에 올라와있는 엔티티 일부를 삭제**](##)하려 할 때 주요하다.<br>  
즉, 관리되는 엔티티 작업 중간에 벌크 작업을 수행할 때이다.<br>
나는 협업에 도움이 되므로 벌크 작업시 @Modifying(clearAutomatically = true, flushAutomatically = true)를 붙이는 것을 선호한다.
<br><br>

---

### Q: 벌크 삭제시 가장 효율적인 방법은?
{:.read-more}

저자는 영속성 콘텍스트, DB 동기화 상관없이 모든 항목을 삭제하는 가장 효율적인 방법은 내장된 [**`deleteAllInBatch()`**](##)를 사용하는 것이라 했는데,<br>
실제 구현을 보고 써보면 deleteAllInBatch()는 [**In이 아닌 Or로 묶어서 삭제**](##)하는 것을 확인할 수 있다.<br>

~~~java
//file: `deleteAllInBatch의 구현체`
@Override
@Transactional
public void deleteAllInBatch(Iterable<T> entities){

        Assert.notNull(entities,"Entities must not be null");

        if(!entities.iterator().hasNext()){
        return;
        }

        applyAndBind(getQueryString(DELETE_ALL_QUERY_STRING,entityInformation.getEntityName()),entities,entityManager)
        .executeUpdate();
        }
~~~

~~~java
//file: `applyAndBind의 구현체`
public static<T> Query applyAndBind(String queryString,Iterable<T> entities,EntityManager entityManager){

        Assert.notNull(queryString,"Querystring must not be null");
        Assert.notNull(entities,"Iterable of entities must not be null");
        Assert.notNull(entityManager,"EntityManager must not be null");

        Iterator<T> iterator=entities.iterator();

        if(!iterator.hasNext()){
        return entityManager.createQuery(queryString);
        }

        String alias=detectAlias(queryString);
        StringBuilder builder=new StringBuilder(queryString);
        builder.append(" where");

        int i=0;

        while(iterator.hasNext()){

        iterator.next();

        builder.append(String.format(" %s = ?%d",alias,++i));


        /**
         * 이부분에서 or 로 연결한다.
         */

        if(iterator.hasNext()){
        builder.append(" or");
        }
        }

        Query query=entityManager.createQuery(builder.toString());

        iterator=entities.iterator();
        i=0;

        while(iterator.hasNext()){
        query.setParameter(++i,iterator.next());
        }

        return query;
        }
~~~

~~~sql
-- file: `authorRepository.deleteAllInBatch(authors)의 쿼리`
delete
from author
where id = ?
   or id = ? -- or로 연결된다.
~~~

**In절로 Bulk삭제하도록 Custom Query를 작성하면 어떻게 될까?**

~~~java
//file: `deleteBulkByAuthors의 구현체`
@Transactional
@Modifying(flushAutomatically = true, clearAutomatically = true)
@Query("DELETE FROM Author a WHERE a IN ?1")
    int deleteBulkByAuthors(List<Author> authors);
~~~

~~~java
//file: `deleteBulkByAuthors의 사용`
@Transactional
public void deleteCustomBulkMethod(){
        List<Author> all=authorRepository.findAll();

        bookRepository.deleteBulkByAuthors(all);
        authorRepository.deleteBulkByAuthors(all);
        }
~~~

~~~sql
-- file: `deleteBulkByAuthors의 쿼리`
delete
from author
where id in (?, ?, ?, ?)
~~~

<br>

**In절이 더 좋은 이유**

|  사용유형  |                                      In                                       |                                          Or                                           |
|:------:|:-----------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------:|
| 시간 복잡도 | 주어진 리스트를 정렬하고 <br/>이진 탐색을 사용하여 값이 리스트에 속하는지 확인.<br/> **O(log n)**의 시간 복잡도를 가짐 |                 리스트의 모든 값들을 각각 비교하여 확인하므로,<br/> **O(n)**의 시간 복잡도를 가짐                  |
| 실제 성능  | **SELECT * FROM item WHERE id IN (1,2,3,...10000)**<br/>10000건당  [0.0433](##) | **SELECT * FROM item WHERE id = 1 OR id = 2 ... id = 10000**<br/>10000건당 [0.1239](##) |

{:.scroll-table-small}
{:.smaller}

[성능 참고 스택오버플로우 자료](https://stackoverflow.com/questions/782915/mysql-or-vs-in-performance)
{:.read-more}

<br>
따라서 저자의 말 대로 내장 **`deleteAllInBatch(Itemable<T> entities)`**를 사용하는 것은 고민해봐야 한다.<br>
최선의 결과를 불러오지 않을 수도 있기 때문.

> deleteInAllBatch의 경우, 내장 기능이기 때문에 flush와 clear하지 않는다.
> {:.note}

### 삭제 방법 정리

**AuthorRepository 메서드**

|              메서드               | 부모 영속성 컨텍스트 상태 | 비고                                                                                                                                                                                                    |
|:------------------------------:|:--------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|         delete(author)         |      로드됨       | 성능 저하, 자식 개수만큼 DELETE                                                                                                                                                                                 |
|     deleteByIdentifier(id)     |    로드되지 않음     | @Transactional<br/>@Modifying(flushAutomatically = true, clearAutomatically = true)<br/>[**@Query("DELETE FROM Author a WHERE a.id = ?1")**](##)<br/>int deleteByIdentifier(Long id);                 |
|  deleteBulkByIdentifier(ids)   |    로드되지 않음     | @Transactional<br/>@Modifying(flushAutomatically = true, clearAutomatically = true)<br/>[**@Query("DELETE FROM Author a WHERE a.id IN ?1")**](##)<br/>int deleteBulkByIdentifier(List<Long> id);      |
|  deleteBulkByAuthors(authors)  |   여러 부모가 로드됨   | @Transactional<br/>@Modifying(flushAutomatically = true, clearAutomatically = true)<br/>[**@Query("DELETE FROM Author a WHERE a IN ?1")**](##)<br/>int deleteBulkByAuthors(Iterable<Author> authors); |
| deleteAllInBatch(authors) - 내장 |   여러 부모가 로드됨   | 재정의 아니면 영속성 컨텍스트랑 동기화 안됨                                                                                                                                                                              |

{:.scroll-table-small}
{:.smaller}

**BookRepository 메서드**

|                메서드                | 자식 영속성 컨텍스트 상태 | 비고                                                                                                                                                                                                           |
|:---------------------------------:|:--------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|   deleteByAuthorIdentifier(id)    |    로드되지 않음     | @Transactional<br/>@Modifying(flushAutomatically = true, clearAutomatically = true)<br/>[**@Query("DELETE FROM Book b WHERE b.author.id = ?1")**](##)<br/>int deleteByAuthorIdentifier(Long id);             |
| deleteBulkByAuthorIdentifier(ids) |    로드되지 않음     | @Transactional<br/>@Modifying(flushAutomatically = true, clearAutomatically = true)<br/>[**@Query("DELETE FROM Book b WHERE b.author.id IN ?1")**](##)<br/>int deleteBulkByAuthorIdentifier(List<Long> id);  |
|   deleteBulkByAuthors(authors)    |    로드되지 않음     | @Transactional<br/> @Modifying(flushAutomatically = true, clearAutomatically = true)<br/>   [**@Query("DELETE FROM Book b WHERE b.author IN ?1")**](##)<br/>  int deleteBulkByAuthors(List<Author> authors); |
|   deleteAllInBatch(books) - 내장    |      로드됨       | 재정의 아니면 영속성 컨텍스트랑 동기화 안됨                                                                                                                                                                                     |

{:.scroll-table-small}
{:.smaller}

주로 영속성 컨텍스트에 로드 됐는지, 안됐는지에 상황에 따라 취사선택하면 된다.<br>
JPQL 쿼리로 재정의해서 당연한 말이겠지만 테스트 결과 [**영속성에 있는 객체나 id로 삭제하나 실제 나가는 쿼리는 동일**](##)하다.<br>

~~~java
//file: `영속성 vs 비영속성 삭제 코드 및 쿼리 비교`
@Transactional
public void deleteViaBulkHardCodedIdentifiers(){
        List<Long> authorsIds=Arrays.asList(1L,4L);

        bookRepository.deleteBulkByAuthorIdentifier(authorsIds);
        authorRepository.deleteBulkByIdentifier(authorsIds);
        }


@Transactional
public void deleteViaBulkByAuthors(){
        List<Author> all=authorRepository.findAllById(List.of(1L,4L));

        bookRepository.deleteBulkByAuthors(all);
        authorRepository.deleteBulkByAuthors(all);
        }
~~~

~~~sql
-- file: `두 메서드가 배출하는 동일한 DELETE 쿼리`
[Hibernate]
delete
from book
where author_id in (?, ?) [Hibernate]
delete
from author
where id in (?, ?)
~~~

신경써야할 건 제약조건 때문에 [자식 먼저 지우고 부모를 지워야 한다.](##)<br><br>

---
그리고 영속성 컨텍스트와 동기화시켜주는 `@Modifying(flushAutomatically = true, clearAutomatically = true)` 설정을 쓰지 않고,
<br>실수로 삭제된 엔티티에 추가적인 작업이 들어가면 오류를 발생시킨다.

~~~java
//file: `[주의] flush, clear 하지 않고 삭제하고 삭제된 엔티티를 손대는 경우 Exception`
@Transactional
public void deleteViaDeleteInBatchX(){
        Author author=authorRepository.findByNameWithBooks("Joana Nimar");

        bookRepository.deleteAllInBatch(author.getBooks());
        authorRepository.deleteAllInBatch(List.of(author));

        // later on, we forgot that this author was deleted
        author.setGenre("Anthology");
        }

        //Exception 발생
        org.springframework.orm.ObjectOptimisticLockingFailureException:Row was updated or deleted by another transaction(or unsaved-value mapping was incorrect):[com.example.practicepersistancelayer.entity.Author#4]
~~~

~~~java
//file: `flush, clear 하여 영속성 컨텍스트에 동기화할 경우 수정 무시` 
@Transactional
public void deleteViaDeleteInBatchX(){
        Author author=authorRepository.findByNameWithBooks("Joana Nimar");

        bookRepository.deleteBulkByAuthors(List.of(author));
        authorRepository.deleteBulkByAuthors(List.of(author));

        // later on, we forgot that this author was deleted
        author.setGenre("Anthology");
        }
~~~

---

## 연관관계 잘 가져오기

### 엔티티 그래프

N+1, lazy loading 문제를 해결하기 위해 엔티티 그래프를 사용한다.<br>

엔티티그래프(fetch plans) :  엔티티와 관련된 연관관계와 하나의 SELECT문에 로드돼야 할 기본적인 필드를 지정한다.
해당 엔티티에 대한 여러 엔티티 그래프를 정의해 다른 엔티티를 연결하며 하위 그래프를 사용해 복잡한 페치 플랜을 만들 수 있다.
재사용이 가능하다.

* FetchType
    * 페치 그래프 : default 설정으로 attributeNodes에 명시된 필드는 EAGER, 나머지는 LAZY
    * 로드 그래프 : attributeNodes에 명시된 필드만 EAGER, 나머지는 기본 설정 따름

@NamedEntityGraph,attributePaths(adhoc EntityGraph), 로 정의

#### @NamedEntityGraph

엔티티에 정의된다.

~~~java
//file: `Author - EntityGraph 정의`
@Entity
@NamedEntityGraph(
        name = "author-books-graph",//고유한 이름
        attributeNodes = {
                @NamedAttributeNode("books")//Author - books 가져와야 할 필드에 대응
        }
)
~~~

~~~java
//file: `AuthorRepository - EntityGraph 사용`
@Override
@Transactional(readOnly = true)
@EntityGraph(value = "author-books-graph",
        type = EntityGraph.EntityGraphType.FETCH)
List<Author> findAll();
~~~

~~~java
//file: `BookRepository - EntityGraph 사용`
@Transactional(readOnly = true)
@EntityGraph(value = "books-author-graph",
        type = EntityGraph.EntityGraphType.FETCH)
@Override
    List<Book> findAll();
~~~

~~~sql
-- file: `EntityGraph 사용시 쿼리`
select
    a1_0.id,
    a1_0.age,
    b1_0.author_id,
    b1_0.id,
    b1_0.isbn,
    b1_0.title,
    a1_0.genre,
    a1_0.name
from
    author a1_0
        left join
    book b1_0
    on a1_0.id=b1_0.author_id
~~~

Author - books 부모 자식간의 연관관계를 가져온다.<br>
그래서 흥미로운 것은 bookRepository.findAll()에 EntityGraph를 적용해도 Author - books를 가져온다.<br>

* 쿼리 메서드 오버라이딩
* 쿼리 빌더 메커니즘
* Specification 사용
* @Query JPQL 사용

다수의 즉시 가져오기를 하는 엔티티 그래프는 주의해야 한다(예 : Author에 Lazy로 선언된 List 두 자식이 있고, 둘 다 엔티티그래프에 포함될 경우)
여러 left outer join로 SELECT 호출되면, 하나 이상의 하이버네이트 Bag(동일한 항목이 제거되지 않고 중복이 허영되는 비정렬 컬렉션 타입)을 즉시 가져오게 되는데,
MultipleBagFetchException이 발생한다. 즉, 엔티티그래프 hint를 사용해 쿼리를 실행할 때 즉시 여러 로딩을 시도하면 하이버네이트는 MultipleBagFetchException을 발생시킨다.

그러나 잘못된 가정으로 MultipleBagFetchException이 엔티티그래프에 한정된 것으로 생각하지 말아야 한다.
여러 개의 즉시 로딩을 시도하는 쿼리를 실행하려고 할 때 마다 나타난다. 특히 이런 종류의 예외는 Page가 있는 Section을 갖는 Chapter를 보유한 Book과 같은 엔티티 계층구조(hierachies)에서 여러 레벨을 가져오는 경우 자주 발생한다.

이 문제에 대한 가장 쉬운 해결책은 Set을 List로 변경하는 것이지만 예상대로 작동함에도 효율적인 솔루션과는 거리가 멀다.
중간 결과 세트를 병합흔 결과인 카테시안 곱이 엄청 크기 때문이다. 일반적으로 얘기해 B와 C의 연관관계를 갖는 A 엔티티를 가져온다고 할 때 10 * 20 * 25 = 5000행이다.
성능이 안좋다. 최상의 해결책은 한번에 하나의 연관관계를 가져오는 것인데, 하나 이상의 쿼리가 필요함을 의미하지만 매우 큰 카테시안 곱을 피할 수 있다.


